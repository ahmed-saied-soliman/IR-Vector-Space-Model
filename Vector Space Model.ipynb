{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadingFromFile():\n",
    "    FilesvsLines={}\n",
    "    NumOfFile=int(input(\"Enter Number Of Files You Will Enter : \"))\n",
    "    for x in range(0,NumOfFile):\n",
    "        NameOfFile=input(\"Enter Name of file : \")\n",
    "        File=open(NameOfFile+\".txt\",'r')\n",
    "        Lines = File.read().splitlines()\n",
    "        FilesvsLines[NameOfFile]=Lines\n",
    "        File.close()\n",
    "    return FilesvsLines,NumOfFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitWords(Words):\n",
    "    TWords=[]\n",
    "    for Word in Words:\n",
    "        TWords.extend(word_tokenize(Word))\n",
    "    return TWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words By NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(words):\n",
    "    filtered_sentence = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence.append(word.capitalize())\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingDocuments():\n",
    "    FilesvsLines,NumOfDocuments=ReadingFromFile()\n",
    "    for key ,value in FilesvsLines.items():\n",
    "        FilesvsLines[key]=RemoveStopWords(SplitWords(value))\n",
    "    return FilesvsLines,NumOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number Of Files You Will Enter : 4\n",
      "Enter Name of file : DOC1\n",
      "Enter Name of file : DOC2\n",
      "Enter Name of file : DOC3\n",
      "Enter Name of file : DOC4\n",
      "{'DOC1': ['English', 'Tutorial'], 'DOC2': ['Advance', 'English'], 'DOC3': ['English', 'Structure'], 'DOC4': ['Tutorial']}\n"
     ]
    }
   ],
   "source": [
    "FilesvsLines,NumOfDocuments=PreprocessingDocuments()\n",
    "print(FilesvsLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create2DArray(FilesvsLines):\n",
    "    array=[]\n",
    "    WordsVSTF={}\n",
    "    for key in FilesvsLines:\n",
    "        for value in FilesvsLines[key]:\n",
    "            array.append(value)\n",
    "    vac=sorted(list(set(array)))\n",
    "    for  x in vac:\n",
    "        for value in FilesvsLines.values():\n",
    "            if(x in value):\n",
    "                if (x in WordsVSTF.keys()):\n",
    "                    WordsVSTF[x].append(1)\n",
    "                else:\n",
    "                    WordsVSTF[x]=[1]\n",
    "            else:\n",
    "                if (x in WordsVSTF.keys()):\n",
    "                    WordsVSTF[x].append(0)\n",
    "                else:\n",
    "                    WordsVSTF[x]=[0]\n",
    "    return WordsVSTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Advance': [0, 1, 0, 0], 'English': [1, 1, 1, 0], 'Structure': [0, 0, 1, 0], 'Tutorial': [1, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "WordsVSTF=create2DArray(FilesvsLines)\n",
    "print(WordsVSTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateIDF(WordsVSTFIDF,NumOfDocuments):\n",
    "    DICTOfIDF={}\n",
    "    for key,value in WordsVSTFIDF.items():\n",
    "        sumo=0\n",
    "        for x in value:\n",
    "            sumo=sumo+x\n",
    "        nsumo=NumOfDocuments/sumo\n",
    "        idf=math.log10(nsumo)\n",
    "        DICTOfIDF[key]=idf\n",
    "        value=list(map(lambda x: x*idf,value))\n",
    "        WordsVSTFIDF[key]=value\n",
    "    return WordsVSTFIDF,DICTOfIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Advance': 0.6020599913279624, 'English': 0.12493873660829993, 'Structure': 0.6020599913279624, 'Tutorial': 0.3010299956639812}\n",
      "{'Advance': [0.0, 0.6020599913279624, 0.0, 0.0], 'English': [0.12493873660829993, 0.12493873660829993, 0.12493873660829993, 0.0], 'Structure': [0.0, 0.0, 0.6020599913279624, 0.0], 'Tutorial': [0.3010299956639812, 0.0, 0.0, 0.3010299956639812]}\n"
     ]
    }
   ],
   "source": [
    "WordsVSTFIDF,DICTOfIDF=CalculateIDF(WordsVSTF,NumOfDocuments)\n",
    "print(DICTOfIDF)\n",
    "print(WordsVSTFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateLengthOfDocuments(WordsVSTFIDF,NumOfDocuments):\n",
    "    LengthOfDocuments=[]\n",
    "    for i in range(0,NumOfDocuments):\n",
    "        sumo=0\n",
    "        for values in WordsVSTFIDF.values():\n",
    "            sumo+=math.pow(values[i],2)\n",
    "        LengthOfDocuments.append(math.sqrt(sumo))\n",
    "    return LengthOfDocuments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32592751678054843, 0.6148869172970786, 0.6148869172970786, 0.3010299956639812]\n"
     ]
    }
   ],
   "source": [
    "LengthOfDocuments=CalculateLengthOfDocuments(WordsVSTFIDF,NumOfDocuments)\n",
    "print(LengthOfDocuments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QueryPreprocessing(DICTOfIDF):\n",
    "    Query=[]\n",
    "    QueryVsTFIDF={}\n",
    "    query=input(\"Enter Your Query : \")\n",
    "    queryterm=RemoveStopWords(query.split(\" \"))\n",
    "    listOfIDF=list(DICTOfIDF.keys())\n",
    "    for x in queryterm:\n",
    "        if(x in listOfIDF):\n",
    "            Query.append(x)\n",
    "    print(Query)        \n",
    "    UniqueQuery=sorted(list(set(Query)))\n",
    "    print(UniqueQuery)\n",
    "    for x in UniqueQuery:\n",
    "        idf=DICTOfIDF.get(x)\n",
    "        QueryVsTFIDF[x]=Query.count(x)*idf\n",
    "    sumo=0    \n",
    "    for x in QueryVsTFIDF.values():\n",
    "        sumo+=math.pow(x,2)\n",
    "    LengthOfQuery=math.sqrt(sumo) \n",
    "    return QueryVsTFIDF,LengthOfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Query : advance Tutorial\n",
      "['Advance', 'Tutorial']\n",
      "['Advance', 'Tutorial']\n",
      "{'Advance': 0.6020599913279624, 'Tutorial': 0.3010299956639812}\n",
      "0.673123533571129\n"
     ]
    }
   ],
   "source": [
    "QueryVsTFIDF,LengthOfQuery=QueryPreprocessing(DICTOfIDF)\n",
    "print(QueryVsTFIDF)\n",
    "print(LengthOfQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateCosineSimilarity(WordsVSTFIDF,LengthOfDocuments,QueryVsTFIDF,LengthOfQuery,NumOfDocuments):\n",
    "    CosineSimilarity={}\n",
    "    for i in range(0,NumOfDocuments):\n",
    "        sumo=0\n",
    "        for key ,value in QueryVsTFIDF.items():\n",
    "            sumo+=WordsVSTFIDF[key][i]*QueryVsTFIDF[key]\n",
    "            \n",
    "        cos=sumo/(LengthOfDocuments[i]*LengthOfQuery)\n",
    "        CosineSimilarity[\"DOC\"+str(i+1)]=cos\n",
    "    sorted_by_value=sorted(CosineSimilarity.items(), key=lambda CosineSimilarity: CosineSimilarity[1],reverse=True)\n",
    "    print(sorted_by_value)\n",
    "    return CosineSimilarity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DOC2', 0.8757688799495646), ('DOC4', 0.4472135954999579), ('DOC1', 0.4130510613035182), ('DOC3', 0.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DOC1': 0.4130510613035182,\n",
       " 'DOC2': 0.8757688799495646,\n",
       " 'DOC3': 0.0,\n",
       " 'DOC4': 0.4472135954999579}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalculateCosineSimilarity(WordsVSTFIDF,LengthOfDocuments,QueryVsTFIDF,LengthOfQuery,NumOfDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
